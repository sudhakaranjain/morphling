mBertBaseline:
  num_epochs: 5
  batch_size: 32
  learning_rate: 0.00001
  base_model: bert-base-multilingual-cased

mMiniLM:
  num_epochs: 20
  batch_size: 32
  token_learning_rate: 0.00001
  sentence_learning_rate: 0.00001
  base_model: microsoft/Multilingual-MiniLM-L12-H384
